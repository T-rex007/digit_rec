{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MP-hmkO9dvg1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tyrel/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OoDBMHFMdvhA"
   },
   "outputs": [],
   "source": [
    "### neural layer # not used\n",
    "def neuron_layer(x, n_neurons, name, activation = None):\n",
    "    with tf.name_scope(name):\n",
    "        n_inputs = int(x.get_shape()[1])\n",
    "        stddev = 2/ np.sqrt(n_inputs)\n",
    "        init = tf.truncated_normal((n_inputs, n_neurons), stddev = stddev)\n",
    "        w = tf.Variable(init, name = \"weights\")\n",
    "        b = tf.Variable(tf.zeros([n_neurons], tf.float32))\n",
    "        z = tf.add(tf.matmul(x,w),b)\n",
    "        if activation == 'relu':\n",
    "            return tf.nn.relu(z)\n",
    "        elif activation == 'softmax': \n",
    "            return tf.nn.softmax(z)\n",
    "        else:\n",
    "            return z\n",
    "        \n",
    "### Loading in and preprocessing the data\n",
    "def load_prep(path, testortrain = 'train' ):\n",
    "    data = pd.read_csv(path)\n",
    "    \n",
    "    from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "    if testortrain == 'train':\n",
    "        features = np.array(data.drop('label', axis = 1))\n",
    "        labels = data.label.values\n",
    "        features = StandardScaler().fit_transform(np.float32(features))\n",
    "        return features, labels\n",
    "    elif testortrain == 'test':\n",
    "        features = np.array(data)\n",
    "        features = StandardScaler().fit_transform(np.float32(features))\n",
    "        return features\n",
    "    else:\n",
    "        print(\"-Test or Train ?\")\n",
    "        return None\n",
    "\n",
    "def leaky_relu(z, name = None):\n",
    "    return tf.maximum(0.01* z, z, name = name)\n",
    "\n",
    "def generator(features, labels, batch_size):\n",
    "    for i in range(0, len(features), batch_size):\n",
    "        yield (features[i:i+batch_size], labels[i:i+batch_size])\n",
    "        \n",
    "def max_norm_regularizer(threshold = 1.0, axes = 1, name ='max_norm', collection = 'max_norm'):\n",
    "    def max_norm(weights):\n",
    "        clipped_weights = tf.clip_by_norm(weights, clip_norm = threshold, axes = axes)\n",
    "        clip_weights = tf.assign(weights, clipped_weights, name =name)\n",
    "        tf.add_to_collection(collection, clip_weights)\n",
    "        return None\n",
    "    return max_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1033
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1295,
     "status": "error",
     "timestamp": 1547857648824,
     "user": {
      "displayName": "shaqeal Cadogan",
      "photoUrl": "https://lh5.googleusercontent.com/-ElhIDm0SpK8/AAAAAAAAAAI/AAAAAAAAC2g/uvEzPBRYlt8/s64/photo.jpg",
      "userId": "18054494821555600959"
     },
     "user_tz": 240
    },
    "id": "XGbyhnlpdvhH",
    "outputId": "259fc1d0-1da7-4a9f-c9c5-8e450d2af5cd"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "features, labels = load_prep(path ='train.csv', testortrain = 'train')\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(features, labels, test_size = .25,\n",
    "                                                shuffle = True, stratify = labels,\n",
    "                                                random_state = 42)\n",
    "\n",
    "n_inputs = features.shape[1]\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 100\n",
    "n_hidden3 = 50\n",
    "n_outputs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 231
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9875,
     "status": "error",
     "timestamp": 1547857658415,
     "user": {
      "displayName": "shaqeal Cadogan",
      "photoUrl": "https://lh5.googleusercontent.com/-ElhIDm0SpK8/AAAAAAAAAAI/AAAAAAAAC2g/uvEzPBRYlt8/s64/photo.jpg",
      "userId": "18054494821555600959"
     },
     "user_tz": 240
    },
    "id": "dGDGntCEdvhQ",
    "outputId": "b05bf0de-be54-4b4c-e3b1-de2ff4e9fbd3"
   },
   "outputs": [],
   "source": [
    "from tensorflow.contrib.layers import batch_norm, dropout\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape = [ None, n_inputs], name = \"x\")\n",
    "yt = tf.placeholder(tf.int64, shape = (None), name = \"ytrue\")\n",
    "\n",
    "is_training = tf.placeholder(tf.bool, shape = (), name ='is_training')\n",
    "keep_prob = 0.8\n",
    "x_drop = dropout(x, keep_prob, is_training = is_training )\n",
    "    \n",
    "from tensorflow.contrib.layers import fully_connected\n",
    "with tf.name_scope('dnn'):\n",
    "    np.random.seed()\n",
    "    he_init = tf.contrib.layers.variance_scaling_initializer()\n",
    "    \n",
    "    hidden1 = fully_connected(x_drop, n_hidden1, weights_initializer = he_init, scope = 'h1',\n",
    "                              activation_fn  = tf.nn.elu)\n",
    "    hidden1_drop = dropout(hidden1, keep_prob, is_training = is_training)\n",
    "    \n",
    "    hidden2 = fully_connected(hidden1_drop, n_hidden2, \n",
    "                              weights_initializer = he_init, scope = 'h2',\n",
    "                              activation_fn = tf.nn.elu)\n",
    "    hidden2_drop = dropout(hidden2, keep_prob, is_training = is_training)\n",
    "    \n",
    "    hidden3 = fully_connected(hidden2, n_hidden3, weights_initializer = he_init, scope = 'h3',\n",
    "                             activation_fn = tf.nn.elu)\n",
    "    hidden3_drop = dropout(hidden3, keep_prob, is_training = is_training)\n",
    "    \n",
    "    logits = fully_connected(hidden3_drop, n_outputs,weights_initializer = he_init,\n",
    "                             scope = 'outputs', activation_fn = None)\n",
    "\n",
    "with tf.name_scope('loss'):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels = yt, logits = logits)\n",
    "    lossb = tf.reduce_mean(xentropy, name = 'avg_xentropy')\n",
    "    reg_loss = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)\n",
    "    loss = tf.add_n([lossb]+ reg_loss, name = 'loss')\n",
    "    \n",
    "learning_rate = 0.001\n",
    "with tf.name_scope('train'):\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate )\n",
    "    traing_op = optimizer.minimize(loss)\n",
    "\n",
    "with tf.name_scope('eval'):\n",
    "    correct = tf.nn.in_top_k(logits, yt, 1)### Chooses the class with the top prediction score\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9hpk8gG1dvhg"
   },
   "outputs": [],
   "source": [
    "###clip_all_weights = tf.get_collection('max_norm')\n",
    "epochs = 80\n",
    "batch_size = 50\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(epochs):\n",
    "        train_gen = generator(xtrain, ytrain, batch_size )\n",
    "        for i in range(len(xtrain)//batch_size):\n",
    "            x_batch, y_batch = next(train_gen)\n",
    "            sess.run(traing_op, feed_dict = {is_training: True, x: x_batch, yt: y_batch})\n",
    "            ###sess.run(clip_all_weights)\n",
    "        acc_train = accuracy.eval(feed_dict = {is_training: False, x: xtrain, yt: ytrain })\n",
    "        acc_test = accuracy.eval(feed_dict = {is_training: False, x: xtest, yt: ytest })\n",
    "        acc_dif = acc_train - acc_test\n",
    "        \n",
    "        print(\"-Epoch: \",epoch, \"Training Accuracy: \", acc_train, \"Test Accuracy: \",\n",
    "              acc_test, \"Difference: \", acc_dif)\n",
    "        \n",
    "        save_path = saver.save(sess, \"Models/my_model.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dpJR5BzRdvhx"
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, 'Models/my_model.ckpt')\n",
    "    z = logits.eval(feed_dict ={x: load_prep(path ='test.csv', testortrain = 'test'),\n",
    "                                is_training: False})\n",
    "    pred = np.argmax(z, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iiDWKgoidvh7"
   },
   "outputs": [],
   "source": [
    "predictions = pd.DataFrame(pred, index = np.arange(1, len(pred)+1), columns = ['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x0a5ioFidviD"
   },
   "outputs": [],
   "source": [
    "predictions.to_csv('predictions/nn_pred.csv', index_label = 'ImageId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f7N3WhM0dviL"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "digit_rec_neural_net.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
